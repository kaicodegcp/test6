#!/bin/bash
set -euo pipefail

echo "=== Ozone DataNode Disk Setup Script ==="

# ---- Disk Devices (Update as per your environment) ----
DISKS=(/dev/sdb /dev/sdc /dev/sdd /dev/sde /dev/sdf /dev/sdg /dev/sdh /dev/sdi /dev/sdj /dev/sdk /dev/sdl)
VGNAME="datavg"

# ---- LV Definitions ----
LVSYSTEM=(
  "lv_var_app_log:1000G:/var/app/log"
  "lv_var_app_lib:100G:/var/app/lib"
  "lv_opt_cloudera:100G:/opt/cloudera"
  "lv_opt_Cloudera:100G:/opt/Cloudera"
)

# Ozone Data Mounts (example 48 mounts from /data/1 ... /data/48)
OZONE_MOUNTS_COUNT=48
OZONE_LV_SIZE="7680G"   # each mount size (adjust based on approval)
OZONE_MOUNT_BASE="/data"
OZONE_PATH_SUFFIX="hadoop-ozone/datanode/data"

# ---- Clean existing LVs and VG ----
echo "=== Cleaning existing LVs and VG ==="
for lv in $(lvs --noheadings -o lv_name $VGNAME 2>/dev/null); do
  lvremove -fy $VGNAME/$lv || true
done
vgremove -fy $VGNAME || true

# ---- Wipe Disks ----
echo "=== Wiping Disks ==="
for disk in "${DISKS[@]}"; do
  echo "Wiping $disk..."
  umount ${disk}* 2>/dev/null || true
  wipefs -a "$disk" || true
  sgdisk --zap-all "$disk" || true
  dd if=/dev/zero of="$disk" bs=1M count=10 status=none || true
  partprobe "$disk" || true
done

# ---- Create PVs and VG ----
echo "=== Creating PVs and VG ==="
for disk in "${DISKS[@]}"; do
  pvcreate "$disk"
done
vgcreate $VGNAME "${DISKS[@]}"

# ---- Create System LVs ----
echo "=== Creating System LVs ==="
for entry in "${LVSYSTEM[@]}"; do
  LVNAME=$(echo $entry | cut -d: -f1)
  LVSIZE=$(echo $entry | cut -d: -f2)
  MOUNTPOINT=$(echo $entry | cut -d: -f3)
  lvcreate -L $LVSIZE -n $LVNAME $VGNAME
  mkfs.ext4 -m 0 -F /dev/$VGNAME/$LVNAME
  mkdir -p $MOUNTPOINT
done

# ---- Create Ozone Data LVs ----
echo "=== Creating Ozone Data LVs ==="
for i in $(seq 1 $OZONE_MOUNTS_COUNT); do
  LVNAME="lv_data${i}"
  MOUNTPOINT="${OZONE_MOUNT_BASE}/${i}/${OZONE_PATH_SUFFIX}"
  lvcreate -L $OZONE_LV_SIZE -n $LVNAME $VGNAME
  mkfs.ext4 -m 0 -F /dev/$VGNAME/$LVNAME
  mkdir -p $MOUNTPOINT
done

# ---- Update /etc/fstab ----
echo "=== Updating /etc/fstab ==="
cp /etc/fstab /etc/fstab.bak.$(date +%s)

# Add system mount points
for entry in "${LVSYSTEM[@]}"; do
  LVNAME=$(echo $entry | cut -d: -f1)
  MOUNTPOINT=$(echo $entry | cut -d: -f3)
  echo "/dev/$VGNAME/$LVNAME $MOUNTPOINT ext4 defaults,noatime 0 0" >> /etc/fstab
done

# Add ozone mounts
for i in $(seq 1 $OZONE_MOUNTS_COUNT); do
  LVNAME="lv_data${i}"
  MOUNTPOINT="${OZONE_MOUNT_BASE}/${i}/${OZONE_PATH_SUFFIX}"
  echo "/dev/$VGNAME/$LVNAME $MOUNTPOINT ext4 defaults,noatime 0 0" >> /etc/fstab
done

# ---- Mount Filesystems ----
echo "=== Mounting Filesystems ==="
mount -a

echo "=== Final df -h ==="
df -h | grep -E "$OZONE_MOUNT_BASE|/var/app|/opt/cloudera"



Check if /dev/sdk or /dev/sdl is mounted or in use
bash
Copy
Edit
lsblk /dev/sdk
lsblk /dev/sdl
mount | grep sdk
mount | grep sdl
pvs | grep -E "sdk|sdl"
2. Force remove old LVM signature
bash
Copy
Edit
vgchange -an  # deactivate any VG
pvremove -f /dev/sdk
pvremove -f /dev/sdl
wipefs -a /dev/sdk
wipefs -a /dev/sdl
dd if=/dev/zero of=/dev/sdk bs=1M count=10 status=none
dd if=/dev/zero of=/dev/sdl bs=1M count=10 status=none
3. Rerun your script
Now that gdisk is installed and signatures cleared, rerun:

bash
Copy
Edit
./oz1.sh



Deactivate the specific VGs (not all)
bash
Copy
Edit
vgchange -an datavg1
vgchange -an datavg2
2. Remove LVs and PVs associated with /dev/sdk and /dev/sdl
bash
Copy
Edit
lvremove -f datavg1/var_app_log
lvremove -f datavg1/var_app_lib
lvremove -f datavg2/opt_cloudera
lvremove -f datavg2/opt_Cloudera

vgremove -f datavg1
vgremove -f datavg2

pvremove -f /dev/sdk
pvremove -f /dev/sdl
3. Clear old signatures
bash
Copy
Edit
wipefs -a /dev/sdk
wipefs -a /dev/sdl
dd if=/dev/zero of=/dev/sdk bs=1M count=10 status=none
dd if=/dev/zero of=/dev/sdl bs=1M count=10 status=none
